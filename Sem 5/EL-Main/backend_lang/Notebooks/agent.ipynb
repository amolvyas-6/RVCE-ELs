{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09ff065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\All Projects\\Group\\AI-Lawyer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List, Literal, Sequence, NotRequired, Dict\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import mimetypes\n",
    "from analyse import analyse\n",
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0edcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762fb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    evidence: str\n",
    "    Full_docs: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41945c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidenceClass(TypedDict, total=False):\n",
    "    photographs_and_videos: NotRequired[List[str]]\n",
    "    official_reports: NotRequired[List[str]]\n",
    "    contracts_and_agreements: NotRequired[List[str]]\n",
    "    financial_records: NotRequired[List[str]]\n",
    "    affidavits_and_statements: NotRequired[List[str]]\n",
    "    digital_communications: NotRequired[List[str]]\n",
    "    call_detail_records: NotRequired[List[str]]\n",
    "    forensic_reports: NotRequired[List[str]]\n",
    "    expert_opinions: NotRequired[List[str]]\n",
    "    physical_object_descriptions: NotRequired[List[str]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409783f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def evidence(evidences: EvidenceClass) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to save a categorized summary of all evidence found in the documents.\n",
    "\n",
    "    Analyze the provided text to identify different types of evidence and place a textual\n",
    "    description or summary of each piece into the appropriate list within the EvidenceClass object.\n",
    "\n",
    "    Args:\n",
    "        evidences: A structured object for categorizing evidence.\n",
    "            - photographs_and_videos: Describe any mentioned photos, CCTV footage, or video recordings.\n",
    "            - official_reports: Summarize findings from Police Reports (FIRs), medical reports, etc.\n",
    "            - contracts_and_agreements: Note any mentioned contracts, deeds, or agreements.\n",
    "            - digital_communications: Add transcripts or summaries of emails, WhatsApp chats, or SMS.\n",
    "            - forensic_reports: Describe findings from DNA, fingerprint, or ballistics reports.\n",
    "    \"\"\"\n",
    "    global evidence\n",
    "    evidence = evidences\n",
    "    return \"Successfully Added the Evidences to Database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PublicInfoClass(TypedDict, total=False):\n",
    "    court_details: NotRequired[Dict[str, str]] #court location and court information(judges and all)\n",
    "    parties: NotRequired[Dict[str, List[str]]] #primary litigants like Plaintiff vs. Defendant\n",
    "    case_type: NotRequired[str] #like civil case\n",
    "    case_status: NotRequired[str] \n",
    "    case_summary: NotRequired[str]\n",
    "    timeline_of_proceedings: NotRequired[List[Dict[str, str]]]\n",
    "public = PublicInfoClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool \n",
    "def public(public_info: PublicInfoClass)->str:\n",
    "    \"\"\"\n",
    "    Use this tool to save all publicly available information about a legal case.\n",
    "\n",
    "    This tool captures key details like case numbers, court information, involved parties,\n",
    "    and a summary of the proceedings. Populate all fields of the PublicInfoClass object\n",
    "    based on the text provided.\n",
    "\n",
    "    Args:\n",
    "        public_info: A structured object containing all public details.\n",
    "            - court_details: Identify the court name and presiding judge.\n",
    "            - parties: List the names of the plaintiff/petitioner and defendant/respondent.\n",
    "            - case_type: Classify the case into one of the following categories: [Civil, Criminal, Constitutional, etc.].\n",
    "            - case_status: Determine if the case is Pending, Disposed, etc.\n",
    "            - case_summary: Write a in depth, neutral summary of the publically available case facts.\n",
    "            - timeline_of_proceedings: Create a log of important dates and events.\n",
    "    Returns:\n",
    "        A success message indicating that the publicly releasable information was added to the database.\n",
    "    \"\"\"\n",
    "    global public\n",
    "    public = public_info\n",
    "    return \"Successfully Added the public information to Database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da392e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonDetail(TypedDict, total=False):\n",
    "    \"\"\"Holds detailed personal information for private use.\"\"\"\n",
    "    role: NotRequired[str]               # e.g., \"Client\", \"Witness\", \"Opposing Party\"\n",
    "    name: NotRequired[str]\n",
    "    phone_number: NotRequired[str]\n",
    "    email_address: NotRequired[str]\n",
    "    address: NotRequired[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d29dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivateInfoClass(TypedDict, total=False):\n",
    "    evidence_summary: NotRequired[str]\n",
    "    confidential_contacts: NotRequired[List[PersonDetail]]\n",
    "    privileged_communications: NotRequired[Dict[str, str]]  #Key is betwen whom communication happened, value is communication summary\n",
    "    legal_strategy_and_notes: NotRequired[str]   # Internal memos, argument outlines, case strategy, legal research notes.\n",
    "\n",
    "privateinfo = PrivateInfoClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def private(private_info: PrivateInfoClass) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to save confidential and privileged information not for public disclosure.\n",
    "\n",
    "    This tool is for sensitive data like client details, internal legal strategy, and\n",
    "    summaries of attorney-client communications.\n",
    "\n",
    "    Args:\n",
    "        private_info: A structured object for all confidential information.\n",
    "            - evidence_summary: Populate this using the detailed EvidenceClass structure.\n",
    "            - confidential_contacts: Extract detailed personal info (name, role, contact details) for clients, witnesses, etc.\n",
    "            - privileged_communications: Record summaries of confidential talks. The dictionary key should be the parties involved (e.g., \"Lawyer-Client John Doe\"), and the value should be a summary of the communication.\n",
    "            - legal_strategy_and_notes: Summarize internal memos, argument outlines, and case strategy notes.\n",
    "    \"\"\"\n",
    "    global privateinfo\n",
    "    privateinfo = private_info\n",
    "    return \"Successfully Added the private information to Database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29caa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [evidence, public, private]\n",
    "llm_withtools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad50975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassyAgent(state: Agentstate)->AgentState:\n",
    "    evidence_text = state['evidence']\n",
    "    full_docs_text = state['Full_docs']\n",
    "    SystemPrompt = SystemMessage(content=f\"\"\"\n",
    "You are an expert legal assistant AI. ðŸ¤–\n",
    "\n",
    "Your primary function is to meticulously analyze provided legal texts, extract key information, and categorize it using your available tools. You will be given two distinct sets of text: one containing documents identified as evidence, and another containing the rest of the general case files.\n",
    "\n",
    "Your workflow is as follows:\n",
    "1.  **Analyze Everything:** First, thoroughly review all the text from both the evidence and the general documents to get a complete picture of the case.\n",
    "2.  **Use All Tools:** Your goal is to accurately populate and call all three of your tools: `save_public_case_information`, `save_evidence_summary`, and `save_private_case_information`.\n",
    "3.  **Tool Calls Only:** Do not provide summaries or answer questions in plain text. Your entire response must be the necessary tool calls to structure the extracted data.\n",
    "4.  **Be Comprehensive:** Ensure you extract all relevant details to populate every possible field in the schemas for each tool. Do not leave any relevant information behind.\n",
    "    \"\"\")\n",
    "\n",
    "    HumanPrompt = HumanMessage(content= f\"\"\"\n",
    "Here are the digitized texts from a legal case file. The content is separated into evidence-specific documents and general case documents.\n",
    "\n",
    "Please process all the information and categorize it using your tools.\n",
    "\n",
    "---\n",
    "## Evidence Documents\n",
    "---\n",
    "{evidence_text}\n",
    "\n",
    "---\n",
    "## General Case Documents\n",
    "---\n",
    "{full_docs_text}\n",
    "    \"\"\")\n",
    "    response = llm_withtools.invoke([SystemPrompt, HumanPrompt] + state['messages'])\n",
    "\n",
    "    return {\"messages\" : [response] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: AgentState)->str:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"call_tool\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "Tooler = ToolNode(tools=tools)\n",
    "\n",
    "graph.add_node(\"ClassyAgent\", ClassyAgent)\n",
    "graph.add_node(\"Tooler\", Tooler)\n",
    "\n",
    "graph.add_edge(START, \"ClassyAgent\")\n",
    "graph.add_edge(\"Tooler\", \"ClassyAgent\")\n",
    "graph.add_conditional_edges(\n",
    "    \"ClassyAgent\",\n",
    "    router,\n",
    "    {\n",
    "        \"call_tool\" : \"Tooler\",\n",
    "        \"end\" : END\n",
    "    }\n",
    ")\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92fc0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import mimetypes\n",
    "import re\n",
    "\n",
    "def process_file(file_path):\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    if mime_type is None:\n",
    "        return None\n",
    "\n",
    "    elif mime_type.startswith(\"image/\"):\n",
    "        return analyse(file_path)\n",
    "\n",
    "    elif mime_type == \"application/pdf\":\n",
    "        pdf_document = fitz.open(file_path)\n",
    "        pages_text = []\n",
    "\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            text = page.get_text(\"text\")\n",
    "            if not text.strip():\n",
    "                pix = page.get_pixmap()\n",
    "                img_path = f\"temp_page_{page_num}.png\"\n",
    "                pix.save(img_path)\n",
    "                text = analyse(img_path)\n",
    "\n",
    "            pages_text.append(text)\n",
    "\n",
    "        pdf_document.close()\n",
    "\n",
    "        full_text = \"\\n\".join(pages_text)\n",
    "        processed_text = re.sub(r' {2,}', ' ', full_text)\n",
    "        processed_text = re.sub(r'(\\s*\\n\\s*){2,}', '\\n', processed_text)\n",
    "        final_text = processed_text.strip()\n",
    "\n",
    "        return final_text\n",
    "\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf11842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(evidence_file, Rest_docs_files):\n",
    "    evidence_files = evidence_file\n",
    "    rest_files = Rest_docs_files\n",
    "    evi_len = len(evidence_files)\n",
    "    rest_len = len(rest_files)\n",
    "    evi_dict = {}\n",
    "    rest_dict = {}\n",
    "    for i in range(evi_len):\n",
    "        #i is 1 document\n",
    "        processed_data = process_file(evidence_files[i])\n",
    "        if processed_data is not None:\n",
    "            evi_dict[i] = processed_data\n",
    "    for j in range(rest_len):\n",
    "        processed_data = process_file(rest_files[j])\n",
    "        if processed_data is not None:\n",
    "            rest_dict[j] = processed_data\n",
    "    string_dig_evidence = \" \".join(evi_dict.values())\n",
    "    string_dig_rest = \" \".join(rest_dict.values())\n",
    "    return evi_dict, rest_dict, string_dig_evidence, string_dig_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classified_data(incoming_data: str)->str:\n",
    "    Database = json.loads(incoming_data)\n",
    "    dig_evidence = str\n",
    "    dig_rest = str\n",
    "    global evidence\n",
    "    global public\n",
    "    global privateinfo\n",
    "    #dig_evidence and dig_rest are doc type byt digital, while string_dig_evidence, string_dig_rest are combined + in single string\n",
    "    dig_evidence, dig_rest, string_dig_evidence, string_dig_rest = preprocess_data(Database['evidence'], Database['Full_docs'])\n",
    "    app.invoke({\"messages\":[HumanMessage(content=\"Start the Analysis\")],\n",
    "        \"evidence\" : string_dig_evidence, \n",
    "        \"Full_docs\" : string_dig_rest\n",
    "    })\n",
    "    finalised = {\n",
    "        \"CaseID\" : Database[\"CaseID\"],\n",
    "        \"LawyerID\": Database[\"LawyerID\"],\n",
    "        \"JudgeID\" : Database[\"JudgeID\"],\n",
    "        \"Evidence\" : evidence,\n",
    "        \"Public\" : public,\n",
    "        \"Private\" : private,\n",
    "\n",
    "    }\n",
    "    return json.dumps(finalised)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
